# Projeto: Mapeamento de Comportamento com Autoencoder e KMeans

## Etapas Desenvolvidas

---

### 1. Pr√©-processamento e Enriquecimento dos Dados

A base original foi enriquecida com vari√°veis temporais derivadas da data da transa√ß√£o:

- Dia da semana (segunda a domingo)
- Faixa hor√°ria (madrugada, manh√£, tarde, noite)
- Flag fim de semana

As vari√°veis categ√≥ricas foram transformadas em vari√°veis num√©ricas via OneHotEncoder, enquanto as vari√°veis num√©ricas foram normalizadas com RobustScaler.

---

### 2. Representa√ß√£o Comportamental com Autoencoder

O autoencoder √© uma rede neural n√£o supervisionada usada para aprender os padr√µes normais de transa√ß√µes.

- **Encoder**: comprime os dados em um vetor latente de 3 dimens√µes.
- **Decoder**: reconstr√≥i a transa√ß√£o original.

O erro de reconstru√ß√£o representa o quanto uma transa√ß√£o se desvia do padr√£o aprendido:

- Erros baixos ‚Üí transa√ß√µes comuns
- Erros altos ‚Üí transa√ß√µes an√¥malas

---

### 3. Clusteriza√ß√£o com KMeans

Os vetores latentes foram agrupados com **KMeans (k=2)** para identificar grupos comportamentais distintos.  
Cada transa√ß√£o recebeu o r√≥tulo `cluster_autoencoder`.

---

### Valida√ß√£o Estat√≠stica dos Clusters

Para confirmar que os clusters representam grupos distintos, foram aplicadas duas an√°lises:

- **ANOVA**: indicou diferen√ßas significativas (p < 0.0001) nas vari√°veis entre os clusters.  
- **GLM**: confirmou essas diferen√ßas ajustando por fatores como hor√°rio e tipo de transa√ß√£o.

Ambas refor√ßam que os clusters refletem **comportamentos reais e distintos**.

---

### 4. Classifica√ß√£o de Suspeita

Flag baseada no erro de reconstru√ß√£o:

- Alta suspeita: > p95
- M√©dia suspeita: > p90
- Baixa suspeita: > p75
- Nenhuma: abaixo disso

---

### 5. Gera√ß√£o de Perfis Comportamentais

Para cada conta:

- M√©dia de valor transacionado
- Frequ√™ncia por tipo, dia da semana e hor√°rio
- Faixa hor√°ria e dia mais comuns

---

## Etapas Supervisionadas ‚Äì Detec√ß√£o de Anomalias

---

### 1. Constru√ß√£o do R√≥tulo `anomalia_confirmada`

Criado com base em regras:

- Valor alto
- Hor√°rio suspeito
- Frequ√™ncia elevada
- Desvio do cluster (erro ou dist√¢ncia)

Transa√ß√µes com pontua√ß√£o ‚â• 3 receberam `anomalia_confirmada = 1`.

> Ru√≠do artificial de 0,5% foi adicionado para simular incertezas.

---

### 2. Representa√ß√£o com Autoencoder e KMeans

Erro de reconstru√ß√£o e dist√¢ncia ao centr√≥ide dos clusters foram usados como vari√°veis explicativas.

---

### 3. Treinamento do Modelo (XGBoost)

- Modelo: XGBoost
- Balanceamento: SMOTE
- Alvo: `anomalia_confirmada`

**M√©tricas**:

- F1-score
- Recall por grupo sens√≠vel
- Equality of Opportunity

---

### 4. Avalia√ß√£o com M√∫ltiplos Thresholds

Testados thresholds de 0.40 a 0.80:

| Threshold | F1-score | Falsos Negativos | Falsos Positivos | Equality of Opportunity |
|-----------|----------|------------------|------------------|--------------------------|
| 0.40      | 0.9057   | 85.916           | 3.288            | 0.0006                   |
| 0.50      | 0.9045   | 87.191           | 2.999            | 0.0006                   |
| 0.55      | 0.9040   | 87.657           | 2.964            | 0.0006                   |
| **0.60 ‚úÖ** | **0.9035** | **88.051**       | **2.962**         | **0.0005**               |
| 0.70      | 0.9025   | 88.903           | 2.924            | 0.0005                   |
| 0.80      | 0.9019   | 89.451           | 2.922            | 0.0004                   |

---

## Interpreta√ß√£o

- Thresholds baixos ‚Üí mais detec√ß√£o, mais falsos positivos
- Thresholds altos ‚Üí menos falsos positivos, mais falsos negativos
- **Escolha final: threshold = 0.60** (melhor equil√≠brio entre sensibilidade e robustez)

---

## üîó API ‚Äì Endpoints

### `GET /health`  
Verifica se a API est√° online.  
Resposta: `{ "status": "ok" }`

### `POST /inferencia`  
Executa o pipeline completo (comportamento + anomalia) e retorna os resultados.

---
## Estrutura do C√≥digo

- `main.py`:  
  Define os endpoints da API (`/health` e `/inferencia`) e orquestra o pipeline de infer√™ncia.

- `inferencia/`:  
  Diret√≥rio com os pipelines:
  - `inferencia_comportamento.py`: aplica pr√©-processamento, codifica√ß√£o e clusteriza√ß√£o (Autoencoder + KMeans)
  - `inferencia_anomalia.py`: aplica regras e o modelo XGBoost para classificar anomalias

- `modelos/`: 
  - `colunas_scaler.pkl` ‚Äî colunas utilizadas no scaler original  
  - `scaler.pkl` ‚Äî inst√¢ncia do `RobustScaler` treinado  
  - `encoder_horario.pkl` ‚Äî OneHotEncoder para faixas hor√°rias  
  - `encoder_semana.pkl` ‚Äî OneHotEncoder para dias da semana  
  - `encoder_tipo_transacao.pkl` ‚Äî OneHotEncoder para tipo de transa√ß√£o
  - `kmeans_auto.pkl` ‚Äî modelo KMeans treinado sobre os vetores do Autoencoder
  - `modelo_encoder.keras` ‚Äî parte encoder da rede (reduz dimensionalidade)  
  - `modelo_autoencoder.keras` ‚Äî autoencoder completo usado para reconstru√ß√£o
  - `modelo_xgb.pkl` ‚Äî modelo XGBoost final para infer√™ncia de anomalias
---

## requirements.txt

Lista de bibliotecas necess√°rias para execu√ß√£o do projeto:

- `fastapi==0.111.0`  
- `uvicorn==0.30.0`
- `joblib==1.5.0`  
- `scikit-learn==1.6.1`  
- `xgboost==3.0.2`
- `tensorflow==2.19.0`
- `pandas==2.2.3`  
- `numpy==2.1.3`
- `python-dateutil==2.9.0.post0`
